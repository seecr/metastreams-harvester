#!/usr/bin/env python3
## begin license ##
#
# "Metastreams Harvester" is a fork of Meresco Harvester that demonstrates
# the translation of traditional metadata into modern events streams.
#
# Copyright (C) 2021, 2025 Seecr (Seek You Too B.V.) https://seecr.nl
#
# This file is part of "Metastreams Harvester"
#
# "Metastreams Harvester" is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# "Metastreams Harvester" is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with "Metastreams Harvester"; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#
## end license ##

import argparse
import pathlib
import json
from os.path import isfile
from uuid import uuid4


DATADIR = (
    [
        line.strip()
        for line in open("/etc/meresco-harvester/config").readlines()
        if line.startswith("DATADIR=")
    ][0].split("=")[1]
    if isfile("/etc/meresco-harvester/config")
    else "."
)


def newUuid():
    return str(uuid4())


class Domain:
    def __init__(self, data_path, domainId):
        self._data_path = data_path.joinpath(domainId)
        self.id = domainId

    def exists(self):
        return self._data_path.joinpath(f"{self.id}.domain").is_file()

    def domain_data(self):
        return json.loads(self._data_path.joinpath(f"{self.id}.domain").read_text())

    def _all_data(self, key_name, extension, domainPrefix=False):
        result = {}
        prefix = ""
        if domainPrefix:
            prefix = f"{self.id}."
        for anId in self.domain_data()[key_name]:
            result[anId] = json.loads(
                self._data_path.joinpath(f"{prefix}{anId}.{extension}").read_text()
            )
        return result.items()

    def all_mapping_data(self):
        return self._all_data("mappingIds", "mapping")

    def all_target_data(self):
        return self._all_data("targetIds", "target")

    def all_repository_groups_data(self):
        return self._all_data(
            "repositoryGroupIds", "repositoryGroup", domainPrefix=True
        )

    def all_repositories_data(self):
        result = {}
        for fp in self._data_path.iterdir():
            if not (
                fp.name.endswith(".repository") and fp.name.startswith(f"{self.id}.")
            ):
                continue
            data = json.loads(fp.read_text())
            result[data["identifier"]] = data
        return result.items()

    def _set_data(self, identifier, data, extension, domainPrefix=False):
        self._data_path.mkdir(parents=True, exist_ok=True)
        prefix = ""
        if domainPrefix:
            prefix = f"{self.id}."
        data["identifier"] = identifier
        fp =self._data_path.joinpath(f"{prefix}{identifier}.{extension}")
        fp.write_text(
            json.dumps(data, indent=4)
        )
        print(f"Created {fp.as_posix()!r}")

    def set_mapping_data(self, identifier, data):
        return self._set_data(identifier, data, "mapping")

    def set_target_data(self, identifier, data):
        return self._set_data(identifier, data, "target")

    def set_repository_group_data(self, identifier, data):
        return self._set_data(identifier, data, "repositoryGroup", domainPrefix=True)

    def set_repository_data(self, identifier, data):
        return self._set_data(identifier, data, "repository", domainPrefix=True)

    def set_domain_data(self, data):
        return self._set_data(self.id, data, "domain")


def main(data_path, oldDomainId, newDomainId):
    if not oldDomainId or not newDomainId or oldDomainId == newDomainId:
        print("No correct ids")
        return
    oldDomain = Domain(data_path, oldDomainId)
    newDomain = Domain(data_path, newDomainId)
    if not oldDomain.exists():
        print("Domain not found")
        return

    domain = oldDomain.domain_data()

    #
    # Mappings
    #
    newMappingIdsMapping = {}
    for mappingId, mappingData in oldDomain.all_mapping_data():
        newMappingId = newUuid()
        newMappingIdsMapping[mappingId] = newMappingId
        newDomain.set_mapping_data(newMappingId, mappingData)
    domain["mappingIds"] = list(newMappingIdsMapping.values())

    #
    # Targets
    #
    newTargetIdsMapping = {}
    for targetId, targetData in oldDomain.all_target_data():
        newTargetId = newUuid()
        newTargetIdsMapping[targetId] = newTargetId
        newDomain.set_target_data(newTargetId, targetData)
    domain["targetIds"] = list(newTargetIdsMapping.values())

    #
    # RepositoryGroupIds
    #
    for repositoryGroupId, repoGroup in oldDomain.all_repository_groups_data():
        newDomain.set_repository_group_data(repositoryGroupId, repoGroup)

    for repositoryId, repo in oldDomain.all_repositories_data():
        repo["mappingId"] = newMappingIdsMapping.get(repo.get("mappingId"))
        repo["targetId"] = newTargetIdsMapping.get(repo.get("targetId"))
        newDomain.set_repository_data(repositoryId, repo)

    newDomain.set_domain_data(domain)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--data_dir",
        type=pathlib.Path,
        help=f"Datadir, default: {DATADIR!r}",
        default=pathlib.Path(DATADIR),
    )
    parser.add_argument("--srcId", type=str, help="Source identifier", required=True)
    parser.add_argument(
        "--destId", type=str, help="Destination identifier", required=True
    )

    args = parser.parse_args()
    main(data_path=args.data_dir, oldDomainId=args.srcId, newDomainId=args.destId)
